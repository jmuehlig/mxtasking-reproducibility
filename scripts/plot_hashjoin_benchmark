#!/usr/bin/python3

import sys
import re
import pandas
import numpy as np
import argparse
import subprocess
import json

'''
	Dependencies:
		- pandas (pip3 install pandas)
		- numpy (apt-get install python3-numpy)
		- PyGnuplot (pip3 install PyGnuplot)
		- matplotlib (pip3 install matplotlib)
		- python3-tk (apt-get install python3-tk)
'''


def float_from_scientific_notation(throughput) -> float:
	if throughput is None:
		return float(0)
	elif "e" not in throughput:
		return float(throughput.replace(",", ""))
	else:
		exp_regex = re.compile(r"([\d+\.]+)[Ee]\+(\d+)")
		match = exp_regex.match(throughput)
		if match:
			coefficient, exponent = match.groups()
			return float(coefficient) * (10 ** int(exponent))
		else:
			return float(0)


def parse_json_line(line: str):
	iteration = json.loads(line)
	res = {
		"granularity": int(iteration["phase"]),
		"iteration": int(iteration["iteration"]),
		"throughput": float(iteration["throughput"])
	}
	if "instr" in iteration:
		res["instructions"] = float(iteration["instr"])

	if "cycles" in iteration:
		res["cycles"] = float(iteration["cycles"])

	if "memory-stall" in iteration:
		res["memory_stalls"] = float(iteration["memory-stall"])
		
	if "worker-fills" in iteration:
		res["worker_fills"] = float(iteration["worker-fills"])
	return res


def parse_log_file(log_file_path: str) -> list:
	benchmark_items = []

	with open(log_file_path, "r") as log_file:
		for line in log_file:
			benchmark_items.append(parse_json_line(line))

	data = pandas.DataFrame(benchmark_items)
	return data.sort_values(by=['granularity'])


def human_readable_memory_size(memory_size : int) -> str:
	if memory_size >= (1024 * 1024 * 1024):
		return "{}GB".format(int(memory_size / (1024 * 1024 * 1024)))
	elif memory_size >= (1024 * 1024):
		return "{}MB".format(int(memory_size / (1024 * 1024)))
	elif memory_size >= 1024:
		return "{}kB".format(int(memory_size / 1024))
	else:
		return "{}B".format(memory_size)


def human_readable_size(size: int) -> str:
	if size >= 1000000:
		return "{} M".format(int(size / 1000000))
	elif size >= 1000:
		return "{} K".format(int(size / 1000))
	else:
		return "{}".format(size)
		
def prime_factorization(number: int) -> str:
	factor = 0
	while number > 1:
		number /= 2
		factor += 1
		
	return "2^{{{}}}".format(factor)


def plot(data_frame, file_name_template: str):

	grouped_data_frame = data_frame.groupby(['granularity'])['throughput'].agg(['mean']).reset_index()

	script = 'set terminal pdf enhanced font "Verdana,13"\n'
	script += 'set output "{}.pdf"\n\n'.format(file_name_template)

	# Style
	script += 'set title ""\n'
	script += 'set key off\n'
	script += 'set key above\n'

	# x axis
	script += 'set xtics nomirror\n'
	script += 'set xlabel "records / task"\n'

	# y axis
	script += 'set ytics nomirror\n'
	script += 'set ylabel "M records/second"\n'
	script += 'set grid ytics\n'

	data_file_name = "{}.data".format(file_name_template)
	with open(data_file_name, "w") as data_file:
		data_file.write("#granularity\tthroughput\n")
		for granularity in grouped_data_frame.granularity.unique():
			data_file.write("\"{}\"\t{}".format(
				prime_factorization(granularity),
				grouped_data_frame.query('granularity == {}'.format(granularity))["mean"].to_numpy()[0]
			))
			data_file.write("\n")

	script += '\n'
	script += 'plot "{}" using ($2/1000000):xticlabels(1) with linespoints title "hashjoin"'.format(data_file_name, file_name_template)

	script_file_name = "{}.plt".format(file_name_template)
	with open(script_file_name, "w") as gnuplot_file:
		gnuplot_file.write(script)

	subprocess.run(["gnuplot", script_file_name])


parser = argparse.ArgumentParser(description="Plot benchmark results generated by the index benchmark framework.")
parser.add_argument('input_file', metavar='INPUT_FILE', type=str, help='Input file to plot.')
parser.add_argument('-o', dest='output_directory', type=str, help='Output directory', default='./')

arguments = parser.parse_args()
out_file_template = arguments.input_file.replace('.json', '').split('/')[-1]
out_file_template_with_dir = '{}/{}'.format(arguments.output_directory.rstrip('/'), out_file_template)

plot(parse_log_file(arguments.input_file), out_file_template_with_dir)
